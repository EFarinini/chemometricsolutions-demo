# ChemometricSolutions - Modular Web Application

> âš ï¸ **OFFICIAL REPOSITORY** âš ï¸  
> This is the **official and maintained** repository.  
> **DO NOT use** the old repository `FarininiChemometricSolutions/chemometricsolutions-demos` - it is no longer maintained.  
> ğŸ“§ Contact: chemometricsolutions@gmail.com

Professional chemometric analysis tools brought to the web. A comprehensive Streamlit-based platform for PCA, MLR/DoE, data handling, and classification with a fully modular architecture featuring root-level menu modules and shared workspace utilities.

**Live Demo:** https://chemometricsolutions-demo.streamlit.app/  
**GitHub:** https://github.com/EFarinini/chemometricsolutions-demo

---

**ChemometricSolutions** - Making Professional Chemometric Analysis Accessible to Everyone ğŸ§ªğŸ“Šâœ¨

---
## ğŸ“‚ Project Structure

```
chemometricsolutions-demo/
â”‚
â”œâ”€â”€ streamlit_app.py                 # Main entry point (initializes app state)
â”œâ”€â”€ homepage.py                      # Homepage with navigation dashboard
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“Š ROOT-LEVEL MENU MODULES (Main Pages)
â”‚   â”œâ”€â”€ data_handling.py            # Data import/export/transformation
â”‚   â”œâ”€â”€ pca.py                      # Principal Component Analysis
â”‚   â”œâ”€â”€ mlr_doe.py                  # Multiple Linear Regression & Design of Experiments
â”‚   â”œâ”€â”€ multi_doe_page.py           # Advanced multi-factor DoE
â”‚   â”œâ”€â”€ transformations.py          # Data preprocessing & spectral preprocessing
â”‚   â”œâ”€â”€ pca_monitoring_page.py      # Quality Control & Statistical Process Monitoring
â”‚   â”œâ”€â”€ bayesian_optimization_page.py # Bayesian Optimization for experimental design
â”‚   â”œâ”€â”€ classification_page.py      # Classification algorithms (PLS-DA, SIMCA, LDA, KNN)
â”‚   â”œâ”€â”€ calibration_page.py         # PLS Multivariate Calibration
â”‚   â””â”€â”€ univariate_page.py          # Univariate statistical analysis
â”‚
â”œâ”€â”€ ğŸ”§ COMMON UTILITIES (Root-level shared resources)
â”‚   â”œâ”€â”€ color_utils.py              # Color palettes & visualization theme management
â”‚   â”œâ”€â”€ workspace_utils.py          # Workspace management & dataset activation
â”‚   â””â”€â”€ config.py                   # Global configuration settings
â”‚
â””â”€â”€ ğŸ“ MODULES FOLDER (Calculation & Computation Engines)
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ data_handling/              # Data I/O operations (backend for data_handling.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ loaders.py              # Load CSV, Excel, RAW, DAT, SAM files
    â”‚   â”œâ”€â”€ exporters.py            # Export data (Excel, CSV, pickle)
    â”‚   â”œâ”€â”€ transformations.py      # Row/column operations, filtering, reshaping
    â”‚   â”œâ”€â”€ validators.py           # Input validation & error handling
    â”‚   â””â”€â”€ conversions.py          # Format conversions & spectral data handling
    â”‚
    â”œâ”€â”€ pca/                        # Principal Component Analysis (backend for pca.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ calculations.py         # Core PCA, NIPALS, Varimax/Promax rotations
    â”‚   â”œâ”€â”€ diagnostics.py          # TÂ² (Hotelling), Q (SPE) statistics, contributions
    â”‚   â”œâ”€â”€ plots.py                # 2D/3D scores, loadings, biplot, scree plots
    â”‚   â”œâ”€â”€ statistics.py           # Variance explained, eigenvalues, cumulative variance
    â”‚   â”œâ”€â”€ monitoring.py           # PCA monitoring, control charts
    â”‚   â”œâ”€â”€ predictions.py          # Project new samples onto PCA model
    â”‚   â””â”€â”€ model_export.py         # Save/load PCA models
    â”‚
    â”œâ”€â”€ mlr_doe/                    # MLR & DoE (backend for mlr_doe.py, multi_doe_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ doe_generator.py        # Generate factorial designs (2^k, 3^k, mixed-level)
    â”‚   â”œâ”€â”€ mlr_model.py            # MLR computation, coefficients, model equations
    â”‚   â”œâ”€â”€ diagnostics.py          # VIF, residuals, RÂ², RMSE, lack-of-fit tests
    â”‚   â”œâ”€â”€ response_surface.py     # Response surface methodology, 3D surface visualization
    â”‚   â”œâ”€â”€ candidate_points.py     # Optimal experimental point selection
    â”‚   â”œâ”€â”€ confidence_intervals.py # Prediction intervals, uncertainty quantification
    â”‚   â”œâ”€â”€ pareto_optimization.py  # Pareto front analysis for multi-objective optimization
    â”‚   â”œâ”€â”€ surface_analysis.py     # Ridge analysis, optimal regions
    â”‚   â””â”€â”€ model_computation.py    # Model persistence & computation caching
    â”‚
    â”œâ”€â”€ transformations/            # Data preprocessing (backend for transformations.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ scaling.py              # Standardization (z-score), normalization, autoscaling
    â”‚   â”œâ”€â”€ centering.py            # Mean centering, column-wise centering
    â”‚   â”œâ”€â”€ spectral.py             # SNV, MSC, 1st/2nd derivatives, Savitzky-Golay
    â”‚   â”œâ”€â”€ missing_data.py         # Missing value imputation & reconstruction
    â”‚   â”œâ”€â”€ column_transforms.py    # Log, sqrt, box-cox, polynomial transforms
    â”‚   â”œâ”€â”€ row_transforms.py       # Row normalization, outlier detection
    â”‚   â”œâ”€â”€ transform_plots.py      # Before/after transformation visualizations
    â”‚   â””â”€â”€ preset_pipelines.py     # Pre-built transformation workflows
    â”‚
    â”œâ”€â”€ quality_control/            # Statistical Process Monitoring (backend for pca_monitoring_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ pca_monitoring.py       # PCA monitoring model training
    â”‚   â”œâ”€â”€ control_charts.py       # TÂ² and Q control chart generation
    â”‚   â”œâ”€â”€ fault_detection.py      # Fault detection & diagnostics
    â”‚   â”œâ”€â”€ contributions.py        # Contribution plots for TÂ² and Q
    â”‚   â”œâ”€â”€ limits.py               # Control limit calculations (95%, 99% confidence)
    â”‚   â””â”€â”€ performance.py          # False alarm rates, sensitivity analysis
    â”‚
    â”œâ”€â”€ bayesian_optimization/      # BO for experimental design (backend for bayesian_optimization_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ gaussian_process.py     # GP model computation
    â”‚   â”œâ”€â”€ acquisition.py          # Acquisition functions (EI, UCB, POI)
    â”‚   â”œâ”€â”€ optimization.py         # Point optimization & candidate generation
    â”‚   â”œâ”€â”€ sampling.py             # Initial design sampling strategies
    â”‚   â””â”€â”€ convergence.py          # Convergence diagnostics & convergence plots
    â”‚
    â”œâ”€â”€ classification/             # Pattern recognition (backend for classification_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ models.py               # PLS-DA, SIMCA, LDA, KNN classifiers
    â”‚   â”œâ”€â”€ training.py             # Model training, cross-validation, hyperparameter tuning
    â”‚   â”œâ”€â”€ evaluation.py           # Accuracy, precision, recall, F1, confusion matrix, ROC
    â”‚   â”œâ”€â”€ plots.py                # Classification scores, class boundaries, ROC curves
    â”‚   â”œâ”€â”€ diagnostics.py          # Feature importance, model reliability, confusion analysis
    â”‚   â””â”€â”€ predictions.py          # New sample classification & probability estimates
    â”‚
    â”œâ”€â”€ calibration/                # PLS Calibration (backend for calibration_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ pls_regression.py       # PLS1/PLS2 model computation, X/Y loadings & scores
    â”‚   â”œâ”€â”€ calibration.py          # Model calibration, cross-validation, LV selection
    â”‚   â”œâ”€â”€ predictions.py          # Sample predictions, prediction intervals, UQ
    â”‚   â”œâ”€â”€ diagnostics.py          # Model quality (RÂ², RMSEC, RMSECV, RMSEP), outlier detection
    â”‚   â”œâ”€â”€ leverage_analysis.py    # Leverage, Mahalanobis distance, prediction reliability
    â”‚   â””â”€â”€ model_export.py         # Save/load PLS models
    â”‚
    â”œâ”€â”€ univariate/                 # Univariate statistics (backend for univariate_page.py)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ descriptive_stats.py    # Mean, median, std, skewness, kurtosis
    â”‚   â”œâ”€â”€ hypothesis_tests.py     # t-test, ANOVA, Mann-Whitney, Kruskal-Wallis
    â”‚   â”œâ”€â”€ distributions.py        # Distribution fitting, normality tests
    â”‚   â”œâ”€â”€ correlation.py          # Pearson, Spearman correlation matrices
    â”‚   â”œâ”€â”€ plots.py                # Histograms, box plots, Q-Q plots, scatter matrices
    â”‚   â””â”€â”€ outlier_detection.py    # IQR, Z-score, Mahalanobis distance methods
    â”‚
    â””â”€â”€ visualization/              # Unified plotting system (used by all modules)
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ colors.py               # ChemometricSolutions color palette & theme management
        â”œâ”€â”€ plots_common.py         # Base Plotly functions, grid layouts, common formatting
        â”œâ”€â”€ themes.py               # Consistent plot styling, font settings, color schemes
        â””â”€â”€ export_utils.py         # Plot export (PNG, SVG, PDF)
```

---

## ğŸ¯ Workspace & Dataset Management

### **Shared Workspace System** (Root-level utilities)

The application uses a **common workspace** for managing datasets across all modules:

#### **workspace_utils.py**
- `get_workspace_datasets()` - Retrieve all datasets currently in workspace
- `activate_dataset_in_workspace(name, data)` - Set the active dataset
- `get_current_dataset()` - Retrieve the currently active dataset
- `remove_dataset_from_workspace(name)` - Remove a dataset from workspace
- `export_workspace_backup()` - Export all workspace datasets

**Usage Example:**
```python
from workspace_utils import get_current_dataset, activate_dataset_in_workspace
import pandas as pd

# Get current active dataset from workspace
data = get_current_dataset()

# Switch to different dataset
datasets = get_workspace_datasets()
if "my_dataset" in datasets:
    activate_dataset_in_workspace("my_dataset", datasets["my_dataset"])
```

#### **Dataset Flow:**
1. **Data Handling module** imports CSV/Excel â†’ stored in workspace
2. **All other modules** access the same dataset via `workspace_utils.get_current_dataset()`
3. **Sidebar dataset selector** allows switching between loaded datasets
4. **Persistent across modules** - No need to re-import for each analysis

---

## ğŸ”§ Root-Level Menu Modules

### **1. data_handling.py** - Data Import, Export & Management
**Entry Point:** `Main Menu â†’ Data Handling`

**Features:**
- Load CSV, Excel (.xlsx, .xls), RAW (Bruker, JASCO, Perkin-Elmer), DAT, SAM files
- Export to Excel, CSV, pickle formats
- Data preview with statistics (samples, variables, memory usage)
- Row/column transformations, filtering, reshaping
- Workspace dataset management
- Data validation and error reporting

**Backend Connection:** `modules/data_handling/` (loaders.py, exporters.py, transformations.py)

---

### **2. pca.py** - Principal Component Analysis
**Entry Point:** `Main Menu â†’ PCA`

**Features:**
- Complete PCA workflow (centering, scaling, SVD computation)
- Interactive 2D/3D score plots with hovering info
- Loading plots and biplot visualization
- Variance explained analysis with Scree plots
- TÂ² and Q statistics with control limits
- Varimax/Promax rotation options
- Sample contribution analysis

**Backend Connection:** `modules/pca/` (calculations.py, diagnostics.py, plots.py, statistics.py)

---

### **3. mlr_doe.py** - Multiple Linear Regression & Design of Experiments
**Entry Point:** `Main Menu â†’ MLR & DoE`

**Features:**
- Full factorial design generation (2^k, 3^k)
- MLR model fitting with interaction terms
- Response surface visualization (3D plots)
- VIF analysis for multicollinearity
- Residual analysis and diagnostics
- Optimal point prediction

**Backend Connection:** `modules/mlr_doe/` (doe_generator.py, mlr_model.py, diagnostics.py, response_surface.py)

---

### **4. multi_doe_page.py** - Multi-Response DoE
**Entry Point:** `Main Menu â†’ Multi-Response DoE`

**Features:**
- Multiple response optimization
- Desirability functions
- Pareto front visualization
- Trade-off analysis between responses

**Backend Connection:** `modules/mlr_doe/` (pareto_optimization.py, surface_analysis.py)

---

### **5. transformations.py** - Data Preprocessing
**Entry Point:** `Main Menu â†’ Transformations`

**Features:**
- Centering (mean, median)
- Scaling (standardization, normalization, autoscaling)
- Spectral preprocessing (SNV, MSC, derivatives)
- Missing data handling
- Before/after visualization

**Backend Connection:** `modules/transformations/` (scaling.py, centering.py, spectral.py, missing_data.py)

---

### **6. pca_monitoring_page.py** - Quality Control & SPC
**Entry Point:** `Main Menu â†’ Quality Control`

**Features:**
- PCA model training on reference data
- TÂ² and Q control charts
- Real-time monitoring simulation
- Fault detection and diagnosis
- Contribution plots for out-of-control points

**Backend Connection:** `modules/quality_control/` (pca_monitoring.py, control_charts.py, fault_detection.py)

---

### **7. bayesian_optimization_page.py** - Bayesian Optimization
**Entry Point:** `Main Menu â†’ Bayesian Optimization`

**Features:**
- Gaussian Process surrogate model
- Acquisition function visualization (EI, UCB, POI)
- Sequential experimental design
- Convergence analysis

**Backend Connection:** `modules/bayesian_optimization/` (gaussian_process.py, acquisition.py, optimization.py)

---

### **8. classification_page.py** - Classification Methods
**Entry Point:** `Main Menu â†’ Classification`

**Features:**
- PLS-DA (Partial Least Squares Discriminant Analysis)
- SIMCA (Soft Independent Modeling of Class Analogy)
- LDA (Linear Discriminant Analysis)
- KNN (K-Nearest Neighbors)
- Confusion matrix and ROC curves
- Cross-validation metrics

**Backend Connection:** `modules/classification/` (models.py, training.py, evaluation.py, plots.py)

---

### **9. calibration_page.py** - PLS Calibration
**Entry Point:** `Main Menu â†’ Calibration`

**Features:**
- PLS1/PLS2 regression
- Latent variable selection (cross-validation)
- Prediction with uncertainty
- Model diagnostics (RÂ², RMSEC, RMSECV, RMSEP)
- Leverage and influence analysis

**Backend Connection:** `modules/calibration/` (pls_regression.py, calibration.py, predictions.py, diagnostics.py)

---

### **10. univariate_page.py** - Univariate Statistics
**Entry Point:** `Main Menu â†’ Univariate`

**Features:**
- Descriptive statistics
- Hypothesis testing (t-test, ANOVA)
- Distribution fitting
- Correlation analysis
- Outlier detection

**Backend Connection:** `modules/univariate/` (descriptive_stats.py, hypothesis_tests.py, distributions.py)

---

## ğŸ¨ Color Utilities

### **color_utils.py** (Root-level)

Provides unified color palettes for all visualizations:

```python
from color_utils import get_color_palette, get_theme_colors

# Get categorical color palette
colors = get_color_palette('categorical', n_colors=10)

# Get theme-specific colors (dark/light mode)
theme = get_theme_colors(dark_mode=True)
```

**Available Palettes:**
- `categorical` - For discrete groups
- `sequential` - For continuous values
- `diverging` - For values around a midpoint
- `qualitative` - High-contrast categorical

---

## ğŸ”Œ Visualization Module

All plotting is centralized in `modules/visualization/`:

```python
from modules.visualization import plots_common, colors

# Create Plotly figure with ChemometricSolutions theme
theme = colors.get_chemometric_theme()
fig = plots_common.create_blank_figure(theme=theme)
fig.add_trace(...)
fig.update_layout(**theme['layout'])
```

**Unified styling ensures:** Consistent colors, fonts, sizing across all modules âœ“

---

## ğŸ“Š Shared Workspace Architecture

```
Session State (Streamlit)
    â†“
workspace_utils.py (global dataset management)
    â†“
st.session_state['current_dataset'] â† Active dataset
st.session_state['all_datasets'] â† Dict of all loaded datasets
st.session_state['dataset_name'] â† Current dataset name
    â†“
Every module accesses via: get_current_dataset()
```

**Advantage:** Load data once in Data Handling â†’ Use everywhere else. âœ“

---

## ğŸš€ Getting Started

### Installation

```bash
# Clone repository (OFFICIAL REPOSITORY)
git clone https://github.com/EFarinini/chemometricsolutions-demo.git
cd chemometricsolutions-demo

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running Locally

```bash
# Run Streamlit app
streamlit run streamlit_app.py
```

Open browser â†’ `http://localhost:8501`

---

## ğŸ¯ Architecture Best Practices

âœ… **Separation of Concerns:**
- Calculation logic in `modules/`
- UI logic in root-level `.py` files
- Common utilities in root-level `*_utils.py`

âœ… **Module Independence:**
- Each module folder can work standalone
- No circular dependencies
- Shared imports only through `modules/visualization/` and utils

âœ… **Workspace Integration:**
- All data flows through workspace
- No hardcoded file paths
- Session state synchronization across modules

âœ… **Code Reusability:**
- Calculation functions reusable in other projects
- Plotting functions consistent across all modules
- Utility functions generic and well-documented

---

## ğŸ“Š Features Matrix

| Feature | Module | Status |
|---------|--------|--------|
| Data Import/Export | data_handling.py | âœ… Active |
| PCA Analysis | pca.py | âœ… Active |
| PCA Monitoring | pca_monitoring_page.py | âœ… Active |
| MLR & DoE | mlr_doe.py | âœ… Active |
| Multi-Response DoE | multi_doe_page.py | âœ… Active |
| Data Preprocessing | transformations.py | âœ… Active |
| Bayesian Optimization | bayesian_optimization_page.py | âœ… Active |
| Classification | classification_page.py | âœ… Active |
| PLS Calibration | calibration_page.py | âœ… Active |
| Univariate Stats | univariate_page.py | âœ… Active |

---

## ğŸ’» Technology Stack

- **Framework:** Streamlit 1.28+
- **Scientific Computing:** NumPy, SciPy, scikit-learn
- **Data Manipulation:** Pandas
- **Visualization:** Plotly, Matplotlib
- **Deployment:** Streamlit Cloud
- **Python:** 3.9+ (tested on 3.13)

---

## ğŸ“š Documentation

- **Module-Specific Docs:** README.md in each `modules/*/`
- **API Reference:** Docstrings in each function
- **Examples:** See `examples/` folder (if present)
- **Theory:** See `docs/theory.md` (if present)

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Follow code style (PEP 8, type hints, docstrings)
4. Separate calculation logic from UI
5. Update this README
6. Submit Pull Request

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ‘¨â€ğŸ”¬ Author

**Dr. Emanuele Farinini, PhD**  
Chemometrics & Analytical Chemistry Expert

- Website: https://chemometricsolutions.com
- GitHub: https://github.com/EFarinini
- Email: chemometricsolutions@gmail.com

---

## ğŸ™ Acknowledgments

Built with â¤ï¸ using:
- Python, Streamlit, Plotly
- scikit-learn, SciPy, NumPy, Pandas
- Reference implementations: R packages, CAT software, chemometrics literature

---

## ğŸ“ Support

- **Issues:** GitHub Issues
- **Discussions:** GitHub Discussions  
- **Email:** chemometricsolutions@gmail.com
- **Live Demo:** https://chemometricsolutions-demo.streamlit.app
