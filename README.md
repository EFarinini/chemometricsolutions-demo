# ChemometricSolutions - Modular Web Application

Professional chemometric analysis tools brought to the web. A comprehensive Streamlit-based platform for PCA, MLR/DoE, data handling, and classification with a fully modular architecture featuring root-level menu modules and shared workspace utilities.

**Live Demo:** https://chemometricsolutions-demo.streamlit.app/

**GitHub:** https://github.com/EFarinini/chemometricsolutions-demo

---

**ChemometricSolutions** - Making Professional Chemometric Analysis Accessible to Everyone üß™üìä‚ú®

---
## üìÇ Project Structure

```
chemometricsolutions-demos/
‚îÇ
‚îú‚îÄ‚îÄ streamlit_app.py                 # Main entry point (initializes app state)
‚îú‚îÄ‚îÄ homepage.py                      # Homepage with navigation dashboard
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ üìä ROOT-LEVEL MENU MODULES (Main Pages)
‚îÇ   ‚îú‚îÄ‚îÄ data_handling.py            # Data import/export/transformation
‚îÇ   ‚îú‚îÄ‚îÄ pca.py                      # Principal Component Analysis
‚îÇ   ‚îú‚îÄ‚îÄ mlr_doe.py                  # Multiple Linear Regression & Design of Experiments
‚îÇ   ‚îú‚îÄ‚îÄ multi_doe_page.py           # Advanced multi-factor DoE
‚îÇ   ‚îú‚îÄ‚îÄ transformations.py          # Data preprocessing & spectral preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ pca_monitoring_page.py      # Quality Control & Statistical Process Monitoring
‚îÇ   ‚îú‚îÄ‚îÄ bayesian_optimization_page.py # Bayesian Optimization for experimental design
‚îÇ   ‚îú‚îÄ‚îÄ classification_page.py      # Classification algorithms (PLS-DA, SIMCA, LDA, KNN)
‚îÇ   ‚îú‚îÄ‚îÄ calibration_page.py         # PLS Multivariate Calibration
‚îÇ   ‚îî‚îÄ‚îÄ univariate_page.py          # Univariate statistical analysis
‚îÇ
‚îú‚îÄ‚îÄ üîß COMMON UTILITIES (Root-level shared resources)
‚îÇ   ‚îú‚îÄ‚îÄ color_utils.py              # Color palettes & visualization theme management
‚îÇ   ‚îú‚îÄ‚îÄ workspace_utils.py          # Workspace management & dataset activation
‚îÇ   ‚îî‚îÄ‚îÄ config.py                   # Global configuration settings
‚îÇ
‚îî‚îÄ‚îÄ üìÅ MODULES FOLDER (Calculation & Computation Engines)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ data_handling/              # Data I/O operations (backend for data_handling.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ loaders.py              # Load CSV, Excel, RAW, DAT, SAM files
    ‚îÇ   ‚îú‚îÄ‚îÄ exporters.py            # Export data (Excel, CSV, pickle)
    ‚îÇ   ‚îú‚îÄ‚îÄ transformations.py      # Row/column operations, filtering, reshaping
    ‚îÇ   ‚îú‚îÄ‚îÄ validators.py           # Input validation & error handling
    ‚îÇ   ‚îî‚îÄ‚îÄ conversions.py          # Format conversions & spectral data handling
    ‚îÇ
    ‚îú‚îÄ‚îÄ pca/                        # Principal Component Analysis (backend for pca.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ calculations.py         # Core PCA, NIPALS, Varimax/Promax rotations
    ‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py          # T¬≤ (Hotelling), Q (SPE) statistics, contributions
    ‚îÇ   ‚îú‚îÄ‚îÄ plots.py                # 2D/3D scores, loadings, biplot, scree plots
    ‚îÇ   ‚îú‚îÄ‚îÄ statistics.py           # Variance explained, eigenvalues, cumulative variance
    ‚îÇ   ‚îú‚îÄ‚îÄ monitoring.py           # PCA monitoring, control charts
    ‚îÇ   ‚îú‚îÄ‚îÄ predictions.py          # Project new samples onto PCA model
    ‚îÇ   ‚îî‚îÄ‚îÄ model_export.py         # Save/load PCA models
    ‚îÇ
    ‚îú‚îÄ‚îÄ mlr_doe/                    # MLR & DoE (backend for mlr_doe.py, multi_doe_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ doe_generator.py        # Generate factorial designs (2^k, 3^k, mixed-level)
    ‚îÇ   ‚îú‚îÄ‚îÄ mlr_model.py            # MLR computation, coefficients, model equations
    ‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py          # VIF, residuals, R¬≤, RMSE, lack-of-fit tests
    ‚îÇ   ‚îú‚îÄ‚îÄ response_surface.py     # Response surface methodology, 3D surface visualization
    ‚îÇ   ‚îú‚îÄ‚îÄ candidate_points.py     # Optimal experimental point selection
    ‚îÇ   ‚îú‚îÄ‚îÄ confidence_intervals.py # Prediction intervals, uncertainty quantification
    ‚îÇ   ‚îú‚îÄ‚îÄ pareto_optimization.py  # Pareto front analysis for multi-objective optimization
    ‚îÇ   ‚îú‚îÄ‚îÄ surface_analysis.py     # Ridge analysis, optimal regions
    ‚îÇ   ‚îî‚îÄ‚îÄ model_computation.py    # Model persistence & computation caching
    ‚îÇ
    ‚îú‚îÄ‚îÄ transformations/            # Data preprocessing (backend for transformations.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ scaling.py              # Standardization (z-score), normalization, autoscaling
    ‚îÇ   ‚îú‚îÄ‚îÄ centering.py            # Mean centering, column-wise centering
    ‚îÇ   ‚îú‚îÄ‚îÄ spectral.py             # SNV, MSC, 1st/2nd derivatives, Savitzky-Golay
    ‚îÇ   ‚îú‚îÄ‚îÄ missing_data.py         # Missing value imputation & reconstruction
    ‚îÇ   ‚îú‚îÄ‚îÄ column_transforms.py    # Log, sqrt, box-cox, polynomial transforms
    ‚îÇ   ‚îú‚îÄ‚îÄ row_transforms.py       # Row normalization, outlier detection
    ‚îÇ   ‚îú‚îÄ‚îÄ transform_plots.py      # Before/after transformation visualizations
    ‚îÇ   ‚îî‚îÄ‚îÄ preset_pipelines.py     # Pre-built transformation workflows
    ‚îÇ
    ‚îú‚îÄ‚îÄ quality_control/            # Statistical Process Monitoring (backend for pca_monitoring_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ pca_monitoring.py       # PCA monitoring model training
    ‚îÇ   ‚îú‚îÄ‚îÄ control_charts.py       # T¬≤ and Q control chart generation
    ‚îÇ   ‚îú‚îÄ‚îÄ fault_detection.py      # Fault detection & diagnostics
    ‚îÇ   ‚îú‚îÄ‚îÄ contributions.py        # Contribution plots for T¬≤ and Q
    ‚îÇ   ‚îú‚îÄ‚îÄ limits.py               # Control limit calculations (95%, 99% confidence)
    ‚îÇ   ‚îî‚îÄ‚îÄ performance.py          # False alarm rates, sensitivity analysis
    ‚îÇ
    ‚îú‚îÄ‚îÄ bayesian_optimization/      # BO for experimental design (backend for bayesian_optimization_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ gaussian_process.py     # GP model computation
    ‚îÇ   ‚îú‚îÄ‚îÄ acquisition.py          # Acquisition functions (EI, UCB, POI)
    ‚îÇ   ‚îú‚îÄ‚îÄ optimization.py         # Point optimization & candidate generation
    ‚îÇ   ‚îú‚îÄ‚îÄ sampling.py             # Initial design sampling strategies
    ‚îÇ   ‚îî‚îÄ‚îÄ convergence.py          # Convergence diagnostics & convergence plots
    ‚îÇ
    ‚îú‚îÄ‚îÄ classification/             # Pattern recognition (backend for classification_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ models.py               # PLS-DA, SIMCA, LDA, KNN classifiers
    ‚îÇ   ‚îú‚îÄ‚îÄ training.py             # Model training, cross-validation, hyperparameter tuning
    ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py           # Accuracy, precision, recall, F1, confusion matrix, ROC
    ‚îÇ   ‚îú‚îÄ‚îÄ plots.py                # Classification scores, class boundaries, ROC curves
    ‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py          # Feature importance, model reliability, confusion analysis
    ‚îÇ   ‚îî‚îÄ‚îÄ predictions.py          # New sample classification & probability estimates
    ‚îÇ
    ‚îú‚îÄ‚îÄ calibration/                # PLS Calibration (backend for calibration_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ pls_regression.py       # PLS1/PLS2 model computation, X/Y loadings & scores
    ‚îÇ   ‚îú‚îÄ‚îÄ calibration.py          # Model calibration, cross-validation, LV selection
    ‚îÇ   ‚îú‚îÄ‚îÄ predictions.py          # Sample predictions, prediction intervals, UQ
    ‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py          # Model quality (R¬≤, RMSEC, RMSECV, RMSEP), outlier detection
    ‚îÇ   ‚îú‚îÄ‚îÄ leverage_analysis.py    # Leverage, Mahalanobis distance, prediction reliability
    ‚îÇ   ‚îî‚îÄ‚îÄ model_export.py         # Save/load PLS models
    ‚îÇ
    ‚îú‚îÄ‚îÄ univariate/                 # Univariate statistics (backend for univariate_page.py)
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ descriptive_stats.py    # Mean, median, std, skewness, kurtosis
    ‚îÇ   ‚îú‚îÄ‚îÄ hypothesis_tests.py     # t-test, ANOVA, Mann-Whitney, Kruskal-Wallis
    ‚îÇ   ‚îú‚îÄ‚îÄ distributions.py        # Distribution fitting, normality tests
    ‚îÇ   ‚îú‚îÄ‚îÄ correlation.py          # Pearson, Spearman correlation matrices
    ‚îÇ   ‚îú‚îÄ‚îÄ plots.py                # Histograms, box plots, Q-Q plots, scatter matrices
    ‚îÇ   ‚îî‚îÄ‚îÄ outlier_detection.py    # IQR, Z-score, Mahalanobis distance methods
    ‚îÇ
    ‚îî‚îÄ‚îÄ visualization/              # Unified plotting system (used by all modules)
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ colors.py               # ChemometricSolutions color palette & theme management
        ‚îú‚îÄ‚îÄ plots_common.py         # Base Plotly functions, grid layouts, common formatting
        ‚îú‚îÄ‚îÄ themes.py               # Consistent plot styling, font settings, color schemes
        ‚îî‚îÄ‚îÄ export_utils.py         # Plot export (PNG, SVG, PDF)
```

---

## üéØ Workspace & Dataset Management

### **Shared Workspace System** (Root-level utilities)

The application uses a **common workspace** for managing datasets across all modules:

#### **workspace_utils.py**
- `get_workspace_datasets()` - Retrieve all datasets currently in workspace
- `activate_dataset_in_workspace(name, data)` - Set the active dataset
- `get_current_dataset()` - Retrieve the currently active dataset
- `remove_dataset_from_workspace(name)` - Remove a dataset from workspace
- `export_workspace_backup()` - Export all workspace datasets

**Usage Example:**
```python
from workspace_utils import get_current_dataset, activate_dataset_in_workspace
import pandas as pd

# Get current active dataset from workspace
data = get_current_dataset()

# Switch to different dataset
datasets = get_workspace_datasets()
if "my_dataset" in datasets:
    activate_dataset_in_workspace("my_dataset", datasets["my_dataset"])
```

#### **Dataset Flow:**
1. **Data Handling module** imports CSV/Excel ‚Üí stored in workspace
2. **All other modules** access the same dataset via `workspace_utils.get_current_dataset()`
3. **Sidebar dataset selector** allows switching between loaded datasets
4. **Persistent across modules** - No need to re-import for each analysis

---

## üîß Root-Level Menu Modules

### **1. data_handling.py** - Data Import, Export & Management
**Entry Point:** `Main Menu ‚Üí Data Handling`

**Features:**
- Load CSV, Excel (.xlsx, .xls), RAW (Bruker, JASCO, Perkin-Elmer), DAT, SAM files
- Export to Excel, CSV, pickle formats
- Data preview with statistics (samples, variables, memory usage)
- Row/column transformations, filtering, reshaping
- Workspace dataset management
- Data validation and error reporting

**Backend Connection:** `modules/data_handling/` (loaders.py, exporters.py, transformations.py)

**Key Prompts for Development:**

> **Prompt 1:** "In `data_handling.py`, Tab1 "Load Data", add a feature to detect file encoding automatically. Modify: section "File Upload", function should call `loaders.detect_file_encoding()` and display detected encoding to user before loading."

> **Prompt 2:** "In `data_handling.py`, Tab3 "Export Data", add batch export capability. When user selects multiple datasets from workspace, export all to separate files in a ZIP. Modify `exporters.py` to add `export_batch_to_zip(datasets_dict, output_path)` function."

---

### **2. pca.py** - Principal Component Analysis
**Entry Point:** `Main Menu ‚Üí PCA`

**Features:**
- Complete PCA workflow (centering, scaling, SVD computation)
- Interactive 2D/3D score plots with hovering info
- Loading plots and biplot visualization
- Variance explained analysis with Scree plots
- Hotelling's T¬≤ and Q (SPE) statistics
- Contribution analysis for outlier diagnostics
- Varimax/Promax rotation
- Model diagnostics and summary statistics

**Backend Connection:** `modules/pca/` (calculations.py, plots.py, diagnostics.py, statistics.py)

**Key Prompts for Development:**

> **Prompt 3:** "In `pca.py`, Tab2 "Model Diagnostics", add a new section "Outlier Detection" that displays: (1) T¬≤ vs Q scatter plot with control limits, (2) list of samples exceeding limits. Call `diagnostics.get_outliers_t2_q(scores, loadings, confidence=0.95)` and `plots.plot_t2_vs_q(t2_scores, q_scores)` from modules/pca/."

> **Prompt 4:** "In `pca.py`, Tab3 "Loadings", add interactive feature: when user clicks on a variable name in a table, highlight that variable in the loading plot. Use Plotly's `customdata` and event handling to implement this."

---

### **3. mlr_doe.py** - Multiple Linear Regression & Design of Experiments
**Entry Point:** `Main Menu ‚Üí MLR/DOE`

**Features:**
- Candidate point generation for experimental design
- Full factorial design generation (2^k, 3^k)
- MLR model computation with/without interactions
- Response surface 3D visualization
- Model diagnostics (R¬≤, adjusted R¬≤, RMSE, VIF, lack-of-fit)
- Prediction intervals and uncertainty quantification
- Automatic model equation generation

**Backend Connection:** `modules/mlr_doe/` (doe_generator.py, mlr_model.py, response_surface.py, diagnostics.py, candidate_points.py, confidence_intervals.py)

**Key Prompts for Development:**

> **Prompt 5:** "In `mlr_doe.py`, Tab1 "Candidate Points", Section "Point Optimization", add Pareto front visualization for multi-objective optimization. User selects 2-3 response variables ‚Üí display 2D/3D Pareto front. Call `pareto_optimization.compute_pareto_front(response_surfaces, objectives)` and `plots.plot_pareto_front_3d(pareto_points)`."

> **Prompt 6:** "In `mlr_doe.py`, Tab2 "Response Surface", modify Section "Model Equation" to include model validation statistics. Display: R¬≤, Adjusted R¬≤, PRESS, Lack-of-fit F-statistic. Call `diagnostics.get_model_validation_stats(residuals, n_samples, n_factors)` from modules/mlr_doe/diagnostics.py."

---

### **4. multi_doe_page.py** - Multi-Response Design of Experiments
**Entry Point:** `Main Menu ‚Üí Multi-DOE`

**Features:**
- Define X variables once, multiple Y variables simultaneously
- Automatic model fitting for each response variable
- Unified coefficients comparison across all responses
- Parallel response surface analysis (one surface per Y)
- Multi-criteria decision making with Pareto front optimization
- Model diagnostics for each response independently
- Predictions across all models with confidence intervals
- Experimental design matrix generation (standalone tool)
- Export all model results and predictions

**Architecture:**
- Fits multiple **independent MLR models** (one per Y variable)
- All models use the **same X matrix and terms**
- Comparison views show model coefficients side-by-side
- Each response has its own diagnostic plots, surfaces, and predictions

**Backend Modules:**
- `modules/mlr_doe/` - Core MLR computation (reused for each Y)
- `mlr_utils/model_computation_multidoe.py` - Multi-response fitting engine
- `mlr_utils/model_diagnostics_multidoe.py` - Parallel diagnostics
- `mlr_utils/surface_analysis_multidoe.py` - Multi-surface visualization
- `mlr_utils/predictions_multidoe.py` - Unified predictions interface
- `mlr_utils/pareto_ui_multidoe.py` - Multi-objective optimization
- `mlr_utils/export_multidoe.py` - Batch export for all models

**Tabs in Multi-DOE Module:**
1. **Model Computation** - Select X/Y variables, fit all models, view coefficients
2. **Model Diagnostics** - R¬≤, RMSE, VIF, residuals (switchable by response)
3. **Surface Analysis** - 3D response surfaces (one per Y variable)
4. **Predictions** - Predict multiple responses simultaneously
5. **Multi-Criteria Decision Making** - Pareto front, desirability functions
6. **Generate Matrix** - Standalone experimental design tool
7. **Export** - Download models, predictions, and reports

---

### **5. transformations.py** - Data Preprocessing & Spectral Processing
**Entry Point:** `Main Menu ‚Üí Transformations`

**Features:**
- Scaling methods (standardization, normalization, autoscaling)
- Mean centering
- Spectral preprocessing (SNV, MSC, Savitzky-Golay derivatives)
- Missing value imputation
- Transformation visualization (before/after)
- Preset transformation pipelines

**Backend Connection:** `modules/transformations/` (scaling.py, spectral.py, missing_data.py, transform_plots.py)

---

### **6. pca_monitoring_page.py** - Quality Control & Statistical Process Monitoring
**Entry Point:** `Main Menu ‚Üí Quality Control`

**Features:**
- PCA monitoring model from historical data
- T¬≤ and Q control chart visualization
- Real-time sample monitoring against limits
- Automatic pretreatment method detection
- Contribution analysis for fault diagnostics
- Control limit calculation (95%, 99% confidence)

**Backend Connection:** `modules/quality_control/` (pca_monitoring.py, control_charts.py, fault_detection.py, contributions.py)


---

### **7. bayesian_optimization_page.py** - Bayesian Optimization
**Entry Point:** `Main Menu ‚Üí Bayesian Optimization`

**Features:**
- Gaussian Process modeling of response surface
- Acquisition function optimization (EI, UCB, POI)
- Automated optimal point suggestion
- 1D/2D/nD visualization
- Iterative refinement with new experimental data
- Convergence diagnostics

**Backend Connection:** `modules/bayesian_optimization/` (gaussian_process.py, acquisition.py, optimization.py)

---

### **8. classification_page.py** - Classification & Pattern Recognition
**Entry Point:** `Main Menu ‚Üí Classification`

**Features:**
- PLS-DA, SIMCA, LDA, KNN classifiers
- Model training with cross-validation
- Hyperparameter tuning
- Performance metrics (accuracy, precision, recall, F1, ROC)
- Confusion matrix visualization
- Feature importance analysis
- New sample classification

**Backend Connection:** `modules/classification/` (models.py, training.py, evaluation.py, plots.py)

**Key Prompts for Development:**

---

### **9. calibration_page.py** - PLS Multivariate Calibration
**Entry Point:** `Main Menu ‚Üí PLS Calibration`

**Features:**
- PLS1/PLS2 model computation
- Cross-validation with LV selection
- Prediction intervals and uncertainty quantification
- Model quality metrics (R¬≤, RMSEC, RMSECV, RMSEP)
- Outlier detection (Mahalanobis distance, leverage)
- Sample predictions with confidence bands

**Backend Connection:** `modules/calibration/` (pls_regression.py, calibration.py, predictions.py, diagnostics.py)

**Key Prompts for Development:**

---

### **10. univariate_page.py** - Univariate Statistical Analysis
**Entry Point:** `Main Menu ‚Üí Univariate Analysis`

**Features:**
- Descriptive statistics (mean, median, std, skewness, kurtosis)
- Hypothesis testing (t-test, ANOVA, Mann-Whitney, Kruskal-Wallis)
- Distribution fitting and normality tests
- Correlation matrices (Pearson, Spearman)
- Univariate visualizations (histograms, Q-Q plots, box plots)
- Outlier detection methods (IQR, Z-score, Mahalanobis)

**Backend Connection:** `modules/univariate/` (descriptive_stats.py, hypothesis_tests.py, plots.py, outlier_detection.py)

---

## üî® Common Utilities (Root-Level)

### **color_utils.py** - Theme & Color Management
```python
from color_utils import get_theme_colors, apply_streamlit_theme

# Get ChemometricSolutions color palette
colors = get_theme_colors()
primary_blue = colors['primary']
accent_orange = colors['accent']

# Apply theme to Streamlit app
apply_streamlit_theme()
```

**Contains:**
- ChemometricSolutions brand colors (primary blue #2E5293, accent orange #FF6B35)
- Color palettes for plots (discrete, continuous, diverging)
- Theme management functions
- Accessibility-compliant color selections

---

### **workspace_utils.py** - Dataset Management
```python
from workspace_utils import get_current_dataset, activate_dataset_in_workspace

# Access shared dataset
data = get_current_dataset()

# Switch dataset
all_datasets = get_workspace_datasets()
if "backup_data" in all_datasets:
    activate_dataset_in_workspace("backup_data", all_datasets["backup_data"])
```

**Key Functions:**
- `get_workspace_datasets()` - Dict of all workspace datasets
- `get_current_dataset()` - Currently active dataset
- `activate_dataset_in_workspace(name, dataframe)` - Switch active dataset
- `remove_dataset_from_workspace(name)` - Remove dataset
- `get_dataset_info(name)` - Dataset metadata

---

### **config.py** - Global Configuration
```python
import config

# Access app settings
APP_NAME = config.APP_NAME
THEME_COLOR = config.PRIMARY_COLOR
MAX_UPLOAD_SIZE = config.MAX_FILE_SIZE_MB
```

---

## üé® Visualization Module

All plotting is centralized in `modules/visualization/`:

```python
from modules.visualization import plots_common, colors

# Create Plotly figure with ChemometricSolutions theme
theme = colors.get_chemometric_theme()
fig = plots_common.create_blank_figure(theme=theme)
fig.add_trace(...)
fig.update_layout(**theme['layout'])
```

**Unified styling ensures:** Consistent colors, fonts, sizing across all modules ‚úì

---

## üìä Shared Workspace Architecture

```
Session State (Streamlit)
    ‚Üì
workspace_utils.py (global dataset management)
    ‚Üì
st.session_state['current_dataset'] ‚Üê Active dataset
st.session_state['all_datasets'] ‚Üê Dict of all loaded datasets
st.session_state['dataset_name'] ‚Üê Current dataset name
    ‚Üì
Every module accesses via: get_current_dataset()
```

**Advantage:** Load data once in Data Handling ‚Üí Use everywhere else. ‚úì

---

## üöÄ Getting Started

### Installation

```bash
# Clone repository
git clone https://github.com/EFarinini/chemometricsolutions-demo.git
cd chemometricsolutions-demo

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running Locally

```bash
# Run Streamlit app
streamlit run streamlit_app.py
```

Open browser ‚Üí `http://localhost:8501`

---

## üìù Development Quick Start

### **Adding a New Feature to Existing Module**

**Example: Add confidence interval bands to PCA predictions**

1. **Backend calculation** ‚Üí `modules/pca/predictions.py`
   ```python
   def predict_with_ci(pca_model, new_data, confidence=0.95):
       # Implementation here
       return scores, ci_lower, ci_upper
   ```

2. **Frontend UI** ‚Üí `pca.py`
   ```python
   from modules.pca.predictions import predict_with_ci
   
   # In your Streamlit tab:
   scores, ci_lower, ci_upper = predict_with_ci(model, new_data)
   fig = plots.plot_scores_with_ci(scores, ci_lower, ci_upper)
   st.plotly_chart(fig)
   ```

### **Creating a New Module (Advanced)**

1. Create folder `modules/mymodule/`
2. Implement calculation functions (no Streamlit!)
3. Create root-level file `mymodule_page.py` with `show()` function
4. Add import check to `homepage.py`
5. Add button/link to homepage and sidebar navigation
6. Update this README

---

## üéØ Architecture Best Practices

‚úÖ **Separation of Concerns:**
- Calculation logic in `modules/`
- UI logic in root-level `.py` files
- Common utilities in root-level `*_utils.py`

‚úÖ **Module Independence:**
- Each module folder can work standalone
- No circular dependencies
- Shared imports only through `modules/visualization/` and utils

‚úÖ **Workspace Integration:**
- All data flows through workspace
- No hardcoded file paths
- Session state synchronization across modules

‚úÖ **Code Reusability:**
- Calculation functions reusable in other projects
- Plotting functions consistent across all modules
- Utility functions generic and well-documented

---

## üìä Features Matrix

| Feature | Module | Status |
|---------|--------|--------|
| Data Import/Export | data_handling.py | ‚úÖ Active |
| PCA Analysis | pca.py | ‚úÖ Active |
| PCA Monitoring | pca_monitoring_page.py | ‚úÖ Active |
| MLR & DoE | mlr_doe.py | ‚úÖ Active |
| Multi-Response DoE | multi_doe_page.py | ‚úÖ Active |
| Data Preprocessing | transformations.py | ‚úÖ Active |
| Bayesian Optimization | bayesian_optimization_page.py | ‚úÖ Active |
| Classification | classification_page.py | ‚úÖ Active |
| PLS Calibration | calibration_page.py | ‚úÖ Active |
| Univariate Stats | univariate_page.py | ‚úÖ Active |

---

## üíª Technology Stack

- **Framework:** Streamlit 1.28+
- **Scientific Computing:** NumPy, SciPy, scikit-learn
- **Data Manipulation:** Pandas
- **Visualization:** Plotly, Matplotlib
- **Deployment:** Streamlit Cloud
- **Python:** 3.9+ (tested on 3.13)

---

## üìö Documentation

- **Module-Specific Docs:** README.md in each `modules/*/`
- **API Reference:** Docstrings in each function
- **Examples:** See `examples/` folder (if present)
- **Theory:** See `docs/theory.md` (if present)

---

## ü§ù Contributing

Contributions welcome! Please:

1. Fork repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Follow code style (PEP 8, type hints, docstrings)
4. Separate calculation logic from UI
5. Update this README
6. Submit Pull Request

---

## üìÑ License

MIT License - See LICENSE file for details

---

## üë®‚Äçüî¨ Author

**Dr. Emanuele Farinini, PhD**  
Chemometrics & Analytical Chemistry Expert

- Website: https://chemometricsolutions.com
- GitHub: https://github.com/FarininiChemometricSolutions
- Email: chemometricsolutions@gmail.com

---

## üôè Acknowledgments

Built with ‚ù§Ô∏è using:
- Python, Streamlit, Plotly
- scikit-learn, SciPy, NumPy, Pandas
- Reference implementations: R packages, CAT software, chemometrics literature

---

## üìû Support

- **Issues:** GitHub Issues
- **Discussions:** GitHub Discussions  
- **Email:** chemometricsolutions@gmail.com
- **Live Demo:** https://chemometricsolutions-demo.streamlit.app
